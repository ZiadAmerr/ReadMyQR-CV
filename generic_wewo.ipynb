{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define crucial functions to extract the qr code from the image\n",
    "def get_start_and_end_points(img: np.ndarray) -> tuple:\n",
    "    # define all starting points as -1 (not found yet)\n",
    "    start_row = -1\n",
    "    start_col = -1\n",
    "    end_row = -1\n",
    "    end_col = -1\n",
    "\n",
    "    # loop through the image to find the start and end points of the qr code\n",
    "    # what happens here is that, initially, the value of the pixel is 255 (white)\n",
    "    # so we keep looping until we find a pixel that is not white, and thus, we found the start point\n",
    "    # we do the same for the end point, but we loop from the end of the image to the start\n",
    "    # to find the end point. The same goes for the columns using the transpose of the image\n",
    "    # to loop through the columns\n",
    "\n",
    "    # loop through each row of pixels\n",
    "    for row_index, row in enumerate(img):\n",
    "        # for each pixel in that row\n",
    "        for pixel in row:\n",
    "            # if there is a pixel that is not white\n",
    "            if pixel != 255:\n",
    "                # then we found the start row!\n",
    "                start_row = row_index\n",
    "\n",
    "                # break the loop\n",
    "                break\n",
    "\n",
    "        # if after the loop, the start row is still -1, then no non-white pixels were found, and thus we continue to the next row\n",
    "        # otherwise, the next line checks if the start row was found, and if it was, it breaks the outer loop\n",
    "        if start_row != -1:\n",
    "            break\n",
    "\n",
    "    # do the same for the end row, but loop through that row in reverse\n",
    "    for row_index, row in enumerate(img[::-1]):\n",
    "        for pixel in row:\n",
    "            if pixel != 255:\n",
    "                end_row = img.shape[0] - row_index\n",
    "                break\n",
    "        if end_row != -1:\n",
    "            break\n",
    "\n",
    "    # do the same for the columns, but using the transpose of the image\n",
    "    for col_index, col in enumerate(cv2.transpose(img)):\n",
    "        for pixel in col:\n",
    "            if pixel != 255:\n",
    "                start_col = col_index\n",
    "                break\n",
    "        if start_col != -1:\n",
    "            break\n",
    "\n",
    "    # do the same for the end column, but using the transpose of the image and looping in reverse\n",
    "    for col_index, col in enumerate(cv2.transpose(img)[::-1]):\n",
    "        for pixel in col:\n",
    "            if pixel != 255:\n",
    "                end_col = img.shape[1] - col_index\n",
    "                break\n",
    "        if end_col != -1:\n",
    "            break\n",
    "\n",
    "    # return the start and end points\n",
    "    return start_row, start_col, end_row, end_col\n",
    "\n",
    "\n",
    "def apply_kernel(img, kernel):\n",
    "    # Apply filter\n",
    "    filtered = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    # Convert the result back to uint8\n",
    "    back_to_int = np.uint8(np.absolute(filtered))\n",
    "\n",
    "    # Add the Laplacian result to the original image to sharpen it\n",
    "    return cv2.add(img, back_to_int)\n",
    "\n",
    "\n",
    "def get_grid_cell_size_and_num(qr_no_quiet_zone: np.ndarray) -> tuple:\n",
    "    # get the size of the first non-white pixel in the qr code\n",
    "    size = 0\n",
    "    for pixel in qr_no_quiet_zone[0]:\n",
    "        if pixel != 0:\n",
    "            break\n",
    "        size += 1\n",
    "\n",
    "    # The size of the grid cell is the size of the qr code divided by 7, which is the width of the top-left border of the alignment pattern\n",
    "    grid_cell_size = round(size / 7)\n",
    "\n",
    "    # The number of grid cells is the size of the qr code divided by the size of the grid cell\n",
    "    grid_cells_num = round(qr_no_quiet_zone.shape[0] / grid_cell_size)\n",
    "\n",
    "    # return the size of the grid cell and the number of grid cells\n",
    "    return grid_cell_size, grid_cells_num\n",
    "\n",
    "\n",
    "def get_numeric_qr_cells(img: np.ndarray) -> np.ndarray:\n",
    "    # get the start and end idxs of the qr code\n",
    "    start_row, start_col, end_row, end_col = get_start_and_end_points(img)\n",
    "\n",
    "    # get the qr code without the quiet zone\n",
    "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
    "\n",
    "    # get the size of a grid cell and the number of grid cells\n",
    "    grid_cell_size, grid_cells_num = get_grid_cell_size_and_num(\n",
    "        qr_no_quiet_zone)\n",
    "\n",
    "    # reshape the qr code to a 2D array of grid cells\n",
    "    qr_cells = qr_no_quiet_zone.reshape(\n",
    "        (\n",
    "            grid_cells_num,\n",
    "            grid_cell_size,\n",
    "            grid_cells_num,\n",
    "            grid_cell_size,\n",
    "        )\n",
    "    ).swapaxes(1, 2)\n",
    "\n",
    "    # form an empty array to store the numeric values of the qr cells\n",
    "    qr_cells_numeric = np.ndarray(\n",
    "        (grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
    "\n",
    "    # loop through the qr cells and get the median value of each cell\n",
    "    for i, row in enumerate(qr_cells):\n",
    "        for j, cell in enumerate(row):\n",
    "            qr_cells_numeric[i, j] = np.median(cell) // 255\n",
    "\n",
    "    # return the numeric qr cells\n",
    "    return qr_cells_numeric\n",
    "\n",
    "\n",
    "def give_me_circle_mask_nowww(mask_size, radius):\n",
    "    mask = np.zeros(mask_size)\n",
    "    cy = mask.shape[0] // 2\n",
    "    cx = mask.shape[1] // 2\n",
    "    return cv2.circle(mask, (cx, cy), radius, (255, 255, 255), -1).astype(np.uint8)\n",
    "\n",
    "\n",
    "def try_lowpass(dft_img, limit, gaussian: bool = False):\n",
    "    mask = give_me_circle_mask_nowww(dft_img.shape, limit)\n",
    "    if gaussian:\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_lowpass = np.multiply(dft_img_shifted, mask)\n",
    "    plot_shifted_fft_and_ifft(dft_img_shifted_lowpass)\n",
    "\n",
    "\n",
    "def try_highpass(dft_img, limit, gaussian: bool = False, keep_dc: bool = False):\n",
    "    mask = ~give_me_circle_mask_nowww(dft_img.shape, limit)\n",
    "    if gaussian:\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    if keep_dc:\n",
    "        mask[dft_img.shape[0] // 2, dft_img.shape[1] // 2] = 255\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_highpass = np.multiply(dft_img_shifted, mask)\n",
    "    plot_shifted_fft_and_ifft(dft_img_shifted_highpass)\n",
    "\n",
    "    return dft_img_shifted_highpass\n",
    "\n",
    "\n",
    "def plot_shifted_fft_and_ifft(dft_img_shifted):\n",
    "    img = np.fft.ifft2(np.fft.ifftshift(dft_img_shifted))\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 5), nrows=1, ncols=2)\n",
    "    ax1.set(\n",
    "        yticks=[0, img.shape[0] // 2, img.shape[0] - 1],\n",
    "        yticklabels=[-img.shape[0] // 2, 0, img.shape[0] // 2 - 1],\n",
    "    )\n",
    "    ax1.set(\n",
    "        xticks=[0, img.shape[1] // 2, img.shape[1] - 1],\n",
    "        xticklabels=[-img.shape[1] // 2, 0, img.shape[1] // 2 - 1],\n",
    "    )\n",
    "    ax1.imshow(np.abs(dft_img_shifted) ** 0.1, cmap=\"gray\")\n",
    "    ax2.imshow(np.abs(img), cmap=\"gray\")\n",
    "\n",
    "\n",
    "def give_me_circle_mask_nowww(mask_size, radius):\n",
    "    mask = np.zeros(mask_size)\n",
    "    cy = mask.shape[0] // 2\n",
    "    cx = mask.shape[1] // 2\n",
    "    return cv2.circle(mask, (cx, cy), radius, (255, 255, 255), -1).astype(np.uint8)\n",
    "\n",
    "\n",
    "def try_band_remove(\n",
    "    dft_img,\n",
    "    mask,\n",
    "    gaussian: bool = False,\n",
    "    keep_dc: bool = False,\n",
    "    plot: bool = True,\n",
    "    return_dft: bool = False,\n",
    "):\n",
    "    if gaussian:\n",
    "        mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "    if keep_dc:\n",
    "        mask[dft_img.shape[0] // 2, dft_img.shape[1] // 2] = 255\n",
    "    dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "    dft_img_shifted_band_removed = np.multiply(dft_img_shifted, mask)\n",
    "\n",
    "    if plot:\n",
    "        plot_shifted_fft_and_ifft(dft_img_shifted_band_removed)\n",
    "\n",
    "    img = np.fft.ifft2(np.fft.ifftshift(dft_img_shifted_band_removed))\n",
    "\n",
    "    if return_dft:\n",
    "        return dft_img_shifted_band_removed, img\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_rectangle_mask(mask_size, x1, y1, x2, y2):\n",
    "    mask = np.zeros(mask_size)\n",
    "    return cv2.rectangle(mask, (x1, y1), (x2, y2), (255, 255, 255), -1).astype(np.uint8)\n",
    "\n",
    "\n",
    "def get_exclude_freq_mask(shape, center, x_region, y_region):\n",
    "    large_mask = get_rectangle_mask(\n",
    "        shape,\n",
    "        center[1] - x_region[1] // 2,\n",
    "        center[0] - y_region[1] // 2,\n",
    "        center[1] + x_region[1] // 2,\n",
    "        center[0] + y_region[1] // 2,\n",
    "    )\n",
    "    small_mask = ~get_rectangle_mask(\n",
    "        shape,\n",
    "        center[1] - x_region[0] // 2,\n",
    "        center[0] - y_region[0] // 2,\n",
    "        center[1] + x_region[0] // 2,\n",
    "        center[0] + y_region[0] // 2,\n",
    "    )\n",
    "    return ~(large_mask & small_mask)\n",
    "\n",
    "\n",
    "def find_outliers(matrix, threshold=1.5, k=5):\n",
    "    kernel = np.array([[1, 1, 1],\n",
    "                       [1, 0, 1],\n",
    "                       [1, 1, 1]])\n",
    "\n",
    "    neighbor_sum = convolve(matrix, kernel, mode='constant', cval=0.0)\n",
    "    neighbor_count = convolve(np.ones_like(\n",
    "        matrix), kernel, mode='constant', cval=0.0)\n",
    "\n",
    "    neighbor_mean = neighbor_sum / neighbor_count\n",
    "    neighbor_sqr_diff = convolve(\n",
    "        (matrix - neighbor_mean)**2, kernel, mode='constant', cval=0.0)\n",
    "    neighbor_std = np.sqrt(neighbor_sqr_diff / neighbor_count)\n",
    "\n",
    "    outlier_strength = matrix - (neighbor_mean + threshold * neighbor_std)\n",
    "    outlier_coords = np.argwhere(outlier_strength > 0)\n",
    "    outlier_values = outlier_strength[outlier_strength > 0]\n",
    "\n",
    "    sorted_indices = np.argsort(outlier_values)[::-1]\n",
    "    top_k_indices = sorted_indices[:k]\n",
    "\n",
    "    top_k_coords = outlier_coords[top_k_indices]\n",
    "\n",
    "    return top_k_coords\n",
    "\n",
    "\n",
    "def remove_pixels(dft_img, outlier_idxs):\n",
    "    for i, j in outlier_idxs:\n",
    "        if i == 0 and j == 0:\n",
    "            continue\n",
    "\n",
    "        dft_img[i, j] = 0  # mid\n",
    "\n",
    "        if i != 0:\n",
    "            dft_img[i-1, j] = 0  # up\n",
    "        \n",
    "        if j != 0:\n",
    "            dft_img[i, j-1] = 0  # left\n",
    "            \n",
    "        if i != 0 and j != 0:\n",
    "            dft_img[i-1, j-1] = 0  # up-left\n",
    "        \n",
    "        if i != dft_img.shape[0] - 1:  # down\n",
    "            dft_img[i+1, j] = 0\n",
    "        \n",
    "        if j != dft_img.shape[1] - 1:  # right\n",
    "            dft_img[i, j+1] = 0\n",
    "        \n",
    "        if i != dft_img.shape[0] - 1 and j != dft_img.shape[1] - 1:  # down-right\n",
    "            dft_img[i+1, j+1] = 0\n",
    "\n",
    "        if i != 0 and j != dft_img.shape[1] - 1:  # up-right\n",
    "            dft_img[i-1, j+1] = 0\n",
    "\n",
    "        if i != dft_img.shape[0] - 1 and j != 0:  # down-left\n",
    "            dft_img[i+1, j-1] = 0\n",
    "\n",
    "    return dft_img\n",
    "\n",
    "\n",
    "def preprocess_wewo(img_path, k_freq_to_eliminate=None, is_only_in_pipeline=True, use_outliers=False):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    dft_img = np.fft.fft2(img)\n",
    "\n",
    "    # return dft_img, img\n",
    "    if use_outliers:\n",
    "        dft_img_shifted = np.fft.fftshift(dft_img)\n",
    "\n",
    "        outlier_idxs = find_outliers(np.abs(dft_img_shifted), threshold=6, k=5)\n",
    "\n",
    "        dft_img = remove_pixels(dft_img_shifted, outlier_idxs)\n",
    "\n",
    "        img = np.fft.ifft2(np.fft.ifftshift(dft_img))\n",
    "\n",
    "    elif k_freq_to_eliminate is not None:\n",
    "        center = (dft_img.shape[0] // 2, dft_img.shape[1] // 2)\n",
    "\n",
    "        mask = get_exclude_freq_mask(\n",
    "            dft_img.shape, center, (k_freq_to_eliminate,\n",
    "                                    k_freq_to_eliminate + 1), (-1, 1)\n",
    "        )\n",
    "\n",
    "        dft_img, img = try_band_remove(\n",
    "            dft_img, mask, gaussian=False, keep_dc=True, plot=False, return_dft=True\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"You must provide either k_freq_to_eliminate or use_outliers\")\n",
    "\n",
    "    if is_only_in_pipeline:\n",
    "        x = np.abs(img)\n",
    "\n",
    "        x = cv2.normalize(x, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        return cv2.threshold(x, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.65649055+1.14586831e-15j, 21.99662835+1.16321302e-14j,\n",
       "        21.77613447+2.58551506e-14j, ...,  0.93219409+2.23760213e-14j,\n",
       "        -3.3815176 +3.20631870e-14j, -8.04072239+9.54588413e-16j],\n",
       "       [26.67058945-9.78906357e-15j, 23.01402807+1.02538815e-14j,\n",
       "        22.79680129+1.13786863e-14j, ...,  1.93663124+8.07248960e-15j,\n",
       "        -2.37410369+1.39501670e-14j, -8.03008853+9.19982004e-15j],\n",
       "       [29.68489649-7.13823851e-15j, 25.03163582-1.92193258e-15j,\n",
       "        24.8176754 -1.10770985e-14j, ...,  3.94127497+6.67367023e-15j,\n",
       "        -1.36648281-8.25023661e-15j, -6.01924729+4.73022434e-15j],\n",
       "       ...,\n",
       "       [29.61544805-1.58790362e-14j, 24.94568404-9.06439364e-15j,\n",
       "        24.71538578-1.31145846e-14j, ...,  3.92012382+6.56529749e-15j,\n",
       "        -1.40251472-1.02026621e-14j, -6.07137557-6.09799380e-15j],\n",
       "       [26.62891931-8.51986806e-15j, 22.96245568+1.46981111e-14j,\n",
       "        22.73542593+1.64797190e-14j, ...,  1.92394022+8.28162474e-15j,\n",
       "        -2.39572339+1.37211806e-14j, -8.0613663 +8.51124502e-15j],\n",
       "       [25.64260032+5.14211733e-15j, 21.97943733+2.46346326e-14j,\n",
       "        21.75567576+4.30169906e-14j, ...,  0.92796369+3.90798252e-14j,\n",
       "        -3.38872426+4.74241924e-14j, -8.05114845+1.27010516e-14j]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./test_data/11_wewowewo.png\"\n",
    "img = preprocess_wewo(path, use_outliers=True, is_only_in_pipeline=False)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 1001],\n",
       "       [   0,   11],\n",
       "       [   0,  932],\n",
       "       [   0,  955],\n",
       "       [   0,  723]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
